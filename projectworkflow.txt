SEPSIS EARLY WARNING SYSTEM

STEP 1: PROJECT SETUP & ENVIRONMENT
- Create project folder
- Create virtual environment
- python -m venv sepsis-env
- Activate: sepsis-env\Scripts\activate
- Upgrade pip: python -m pip install --upgrade pip
- Install core dependencies
- Install: pip install -r requirements.txt
- Verify: pip list

STEP 2: PROJECT STRUCTURE GENERATION
- Create template.py
- Paste your template code.
- Run template.py

STEP 3: AWS ACCOUNT & S3 SETUP
- Create S3 bucket
- AWS Console → S3 → Create bucket
- Bucket name: sepsis-mlops-data
- Region: us-east-1
-Create folders inside bucket:
  raw-data
  processed-data
  feature-store
  artifacts
  model-registry
-Create IAM user
  AWS Console → IAM → Users → Create user
  Access type: Programmatic access
  Attach policy: AmazonS3FullAccess
  Download credentials CSV.

STEP 4: AWS CLI CONFIGURATION (LOCAL)
- Run: aws configure
- Verify: aws s3 ls

STEP 5: UPLOAD DATASET TO S3
- Assume dataset name: sepsis-data.csv
- Upload: aws s3 cp sepsis-data.csv s3://sepsis-mlops-data/raw-data/
- Verify: aws s3 ls s3://sepsis-mlops-data/raw-data/

STEP 6: LOGGING & EXCEPTION SETUP
- Implement logger.py Use logging module with file + console handler.
- Implement exception.py Create custom exception class.
- Test: python demo.py Check logs printed.

STEP 7: DATA INGESTION (FROM S3)
- Add aws_connection logic using boto3 then aws_storage which perform read or write operation then data access
  which access the data from s3
- add data ingestion portion and check by integrate the training pipeline

STEP 8: DATA VALIDATION
- Define schema in config/schema.yaml.
- Validate: column names,dtypes.label_12h exists,dataset not empty

STEP 9: DATA TRANSFORMATION
- Separate numerical & categorical features.
- One-hot encode categorical features.
- Preserve NaN values (tree models).
- Save transformer object.
- Generate final feature matrices.

STEP 10: MODEL TRAINING
- Train baseline model:HistGradientBoosting or LightGBM.

STEP 11: EXPERIMENT TRACKING (MLFLOW + DAGSHUB)
- Create DagsHub repo.
- Connect MLflow:
- Set tracking URI.
- Log: params,metrics,model,artifacts

STEP 13: MODEL EVALUATION & PUSHER

STEP 15: FASTAPI PREDICTION APP
 - Implement prediction pipeline
 - Implement app.py.
 - Run locally: uvicorn app:app --reload

STEP 16: DOCKERIZATION
 - Build image: docker build -t sepsis-app .
 - Run locally: docker run -p 8000:8000 sepsis-app

STEP 17: CI/CD (GITHUB + EC2)
 - Create EC2 Ubuntu instance.
 - Install Docker on EC2.
 - Setup self-hosted GitHub runner.
 - Create ECR repository.
 - Add GitHub secrets: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION, ECR_REPO
 - Push code → pipeline triggers automatically.